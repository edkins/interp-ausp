{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d62ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Loading model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model gpt2 into EasyTransformer!\n",
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# First we grab the model and the unembedding weight matrix\n",
    "import torch\n",
    "from easy_transformer import EasyTransformer\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print(f\"Using {device} device\")\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "model = EasyTransformer.from_pretrained('gpt2').to(device)\n",
    "\n",
    "# Convenience function for decoding token\n",
    "decode = model.tokenizer.decode\n",
    "encode = model.tokenizer.encode\n",
    "\n",
    "M_to_V = model.unembed.W_U.data\n",
    "d_M = model.cfg.d_model\n",
    "d_V = model.cfg.d_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18528b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 768]) torch.Size([768, 768]) torch.Size([768, 50257]) torch.Size([768, 50257]) torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "V_to_M = torch.nn.functional.normalize(torch.linalg.pinv(M_to_V), dim=1)\n",
    "\n",
    "pca_model = PCA(n_components=d_M)\n",
    "M_to_D = torch.tensor(pca_model.fit_transform(M_to_V), dtype=torch.float)\n",
    "D_to_V = torch.tensor(pca_model.components_, dtype=torch.float)\n",
    "\n",
    "norms = torch.linalg.vector_norm(M_to_D, dim=0)\n",
    "#M_to_D = M_to_D / norms.reshape(1, d_D).expand(d_M, d_D)\n",
    "#D_to_V = D_to_V * norms.reshape(d_D, 1).expand(d_D, d_V)\n",
    "\n",
    "#print(M_to_V)\n",
    "#print(torch.matmul(M_to_D, D_to_V))\n",
    "\n",
    "\n",
    "V_to_D = torch.matmul(V_to_M, M_to_D)\n",
    "d_D = d_M\n",
    "\n",
    "print(V_to_M.shape, M_to_D.shape, D_to_V.shape, M_to_V.shape, V_to_D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93a27bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cat\n",
      "   cat                       634.8876953125\n",
      "   cats                  404.85211181640625\n",
      "   Cat                        401.826171875\n",
      "  Cat                    327.85736083984375\n",
      "  cat                     311.1290283203125\n",
      "   Cats                   273.6062316894531\n",
      "   dog                   254.74285888671875\n",
      "   CAT                      220.56103515625\n",
      "  cats                   218.95774841308594\n",
      "   catcher                 211.718994140625\n",
      "   kittens               210.29351806640625\n",
      "   kitten                202.44485473632812\n",
      "   dogs                  166.30856323242188\n",
      "   animal                 162.6132049560547\n",
      "   pet                   160.79998779296875\n",
      "   goat                    159.751220703125\n",
      "   Dog                   155.82252502441406\n",
      "   rabbit                155.04403686523438\n",
      "   tiger                  149.2018280029297\n",
      "   fel                   142.49505615234375\n",
      "\n",
      " war\n",
      "   war                      575.61865234375\n",
      "   War                   425.15631103515625\n",
      "   wars                   322.0653381347656\n",
      "  war                    319.39300537109375\n",
      "  War                    255.40916442871094\n",
      "   battle                  245.843505859375\n",
      "   conflict              210.33029174804688\n",
      "   Wars                  208.31544494628906\n",
      "   warfare               205.07339477539062\n",
      "   WAR                   202.30018615722656\n",
      "   warrior               170.71511840820312\n",
      "   warriors              167.01564025878906\n",
      "   genocide              164.62213134765625\n",
      "   Battle                  162.943603515625\n",
      "   battlefield               162.6767578125\n",
      "   peace                 161.00888061523438\n",
      "   fight                 159.59317016601562\n",
      "   wartime               159.25033569335938\n",
      "   waging                 157.4219970703125\n",
      "   Vietnam               151.79493713378906\n",
      "\n",
      " banana\n",
      "   banana                   1039.5439453125\n",
      "   bananas                527.4841918945312\n",
      "   Banana                 441.7322082519531\n",
      "   mango                 323.65460205078125\n",
      "   pineapple             319.59832763671875\n",
      "   apple                   285.024658203125\n",
      "   strawberry            279.93316650390625\n",
      "   potato                       261.5859375\n",
      "   coconut                 247.907470703125\n",
      "   peanut                 238.2726287841797\n",
      "   avocado               234.76437377929688\n",
      "   chocolate              227.3436737060547\n",
      "   peach                 217.92117309570312\n",
      "   strawberries          213.66012573242188\n",
      "   gorilla               210.70745849609375\n",
      "   tomato                210.07391357421875\n",
      "   fruit                 207.02908325195312\n",
      "   cinnamon              200.58363342285156\n",
      "   monkey                198.89666748046875\n",
      "   lemon                 196.23513793945312\n",
      "\n",
      " bat\n",
      "   bat                    648.8990478515625\n",
      "   bats                  387.65301513671875\n",
      "   Bat                   266.83990478515625\n",
      "  Bat                    264.54302978515625\n",
      "  bat                     225.3284454345703\n",
      "   batted                 181.1290283203125\n",
      "  BAT                    175.74090576171875\n",
      "   BAT                    172.6558837890625\n",
      "   batting               159.59515380859375\n",
      "   bowling                151.5093994140625\n",
      "   glove                 144.93539428710938\n",
      "   Batman                136.44549560546875\n",
      "   cricket                  135.13916015625\n",
      "   bathing                 133.695556640625\n",
      "   baseball              133.21446228027344\n",
      "   Orioles                133.0828399658203\n",
      "  bats                   131.95896911621094\n",
      "   BA                    130.58914184570312\n",
      "   mouse                 128.51626586914062\n",
      "   bird                  124.69609069824219\n",
      "\n",
      " bark\n",
      "   bark                  495.83709716796875\n",
      "   Bark                  232.86061096191406\n",
      "   barking               207.31765747070312\n",
      "   trunk                  160.3250732421875\n",
      "   canopy                132.93099975585938\n",
      "   yelled                126.23690795898438\n",
      "   shouted               124.22386932373047\n",
      "   stalk                 121.86570739746094\n",
      "   chewing               115.71595764160156\n",
      "   yell                   112.2674560546875\n",
      "   lumber                111.72697448730469\n",
      "   wax                   110.46815490722656\n",
      "   branches              110.02934265136719\n",
      "   sniff                   109.406494140625\n",
      "   timber                   108.88232421875\n",
      "   shr                   108.14776611328125\n",
      "   leaves                106.84603881835938\n",
      "   logs                  106.50491333007812\n",
      "   hus                   105.36524963378906\n",
      "   foliage               103.86371612548828\n",
      "\n",
      " leaves\n",
      "   leaves                 595.3472290039062\n",
      "   Leaves                    368.5224609375\n",
      "   leave                  362.0050048828125\n",
      "   leaving                289.0750427246094\n",
      "   left                    249.465087890625\n",
      "   leaf                  239.75839233398438\n",
      "   foliage                 211.697021484375\n",
      "   Leaving               186.95509338378906\n",
      "   Leaf                  174.84524536132812\n",
      "   plants                174.69097900390625\n",
      "   depart                171.17538452148438\n",
      "   stems                  170.3135986328125\n",
      "   begs                  161.98648071289062\n",
      "   flowers                161.5308837890625\n",
      "   gives                  156.1479949951172\n",
      "   departed               149.6615753173828\n",
      "  leave                      148.5068359375\n",
      "   poses                  140.9373321533203\n",
      "  left                   140.32594299316406\n",
      "   paints                137.93841552734375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_tokens = [' cat', ' war', ' banana', ' bat', ' bark', ' leaves']\n",
    "\n",
    "def print_similar(heading, td):\n",
    "    print(heading)\n",
    "    similarity_vec = torch.matmul(V_to_D, td)\n",
    "    values = [(v.item(), i) for i,v in enumerate(similarity_vec)]\n",
    "    values.sort(reverse=True)\n",
    "    for v,i in values[:20]:\n",
    "        print(f'  {decode(i):20}', f'{v:20}')\n",
    "    print()\n",
    "\n",
    "for tok in example_tokens:\n",
    "    t, = encode(tok)\n",
    "    td = V_to_D[t,:]\n",
    "    print_similar(tok, td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b74c578f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " leaves -  leaf -  stems\n",
      "   leaves                  473.925048828125\n",
      "   leave                   324.559814453125\n",
      "   leaving                  268.76904296875\n",
      "   Leaves                 257.9458923339844\n",
      "   left                  237.17068481445312\n",
      "   Leaving               174.34120178222656\n",
      "   depart                167.43597412109375\n",
      "   gives                 149.91940307617188\n",
      "   departed               135.7659912109375\n",
      "  leave                       132.298828125\n",
      "   begs                  130.66094970703125\n",
      "  left                   127.87675476074219\n",
      "  Left                    127.3669662475586\n",
      "   puts                  125.24998474121094\n",
      "   makes                 122.95455169677734\n",
      "   paints                119.03379821777344\n",
      "  Leave                  117.99737548828125\n",
      "   departure             117.94159698486328\n",
      "   Leave                 116.73554992675781\n",
      "   brings                116.35395812988281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def subtract_meaning(v0, tok):\n",
    "    t1, = encode(tok)\n",
    "    v1 = V_to_D[t1,:]\n",
    "    similarity0 = torch.matmul(V_to_D, v0)\n",
    "    similarity1 = torch.matmul(V_to_D, v1)\n",
    "    ratio = similarity0[t1] / similarity1[t1]\n",
    "    return v0 - ratio * v1\n",
    "\n",
    "start_tok = ' leaves'\n",
    "minus_toks = [' leaf', ' stems']\n",
    "t0, = encode(start_tok)\n",
    "v0 = V_to_D[t0,:]\n",
    "heading = start_tok\n",
    "for minus_tok in minus_toks:\n",
    "    v0 = subtract_meaning(v0, minus_tok)\n",
    "    heading += f' - {minus_tok}'\n",
    "print_similar(heading, v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb4d8861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " leaves -  leave -  begs -  drops\n",
      "   leaves                 387.2460632324219\n",
      "   Leaves                 244.9817352294922\n",
      "   leaf                   185.0762939453125\n",
      "   foliage               166.66305541992188\n",
      "   plants                152.86337280273438\n",
      "   stems                 131.53860473632812\n",
      "   Leaf                  129.63812255859375\n",
      "   flowers               114.71847534179688\n",
      "   left                  114.15510559082031\n",
      "   trees                 107.00654602050781\n",
      "   bloss                 106.58168029785156\n",
      "   branches               98.30564880371094\n",
      "   poses                  97.27914428710938\n",
      "   limbs                  97.08460235595703\n",
      "   flies                  96.93152618408203\n",
      "   logs                    96.4465560913086\n",
      "   shoots                 96.31671142578125\n",
      "   bark                   95.44673919677734\n",
      "   shapes                 94.48100280761719\n",
      "   crosses                94.38465881347656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_tok = ' leaves'\n",
    "minus_toks = [' leave', ' begs', ' drops', ]\n",
    "t0, = encode(start_tok)\n",
    "v0 = V_to_D[t0,:]\n",
    "heading = start_tok\n",
    "for minus_tok in minus_toks:\n",
    "    v0 = subtract_meaning(v0, minus_tok)\n",
    "    heading += f' - {minus_tok}'\n",
    "print_similar(heading, v0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
