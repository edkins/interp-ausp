{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a10b892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Loading model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model gpt2 into EasyTransformer!\n",
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# First we grab the model and the unembedding weight matrix\n",
    "import torch\n",
    "from easy_transformer import EasyTransformer\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print(f\"Using {device} device\")\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "model = EasyTransformer.from_pretrained('gpt2').to(device)\n",
    "\n",
    "# Convenience function for decoding token\n",
    "decode = model.tokenizer.decode\n",
    "encode = model.tokenizer.encode\n",
    "\n",
    "M_to_V = model.unembed.W_U.data\n",
    "d_M = model.cfg.d_model\n",
    "d_V = model.cfg.d_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a60094cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 768]) torch.Size([768, 768]) torch.Size([768, 50257]) torch.Size([768, 50257]) torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "V_to_M = torch.nn.functional.normalize(torch.linalg.pinv(M_to_V), dim=1)\n",
    "\n",
    "pca_model = PCA(n_components=d_M)\n",
    "M_to_D = torch.tensor(pca_model.fit_transform(M_to_V), dtype=torch.float)\n",
    "D_to_V = torch.tensor(pca_model.components_, dtype=torch.float)\n",
    "\n",
    "norms = torch.linalg.vector_norm(M_to_D, dim=0)\n",
    "#M_to_D = M_to_D / norms.reshape(1, d_D).expand(d_M, d_D)\n",
    "#D_to_V = D_to_V * norms.reshape(d_D, 1).expand(d_D, d_V)\n",
    "\n",
    "#print(M_to_V)\n",
    "#print(torch.matmul(M_to_D, D_to_V))\n",
    "\n",
    "\n",
    "V_to_D = torch.matmul(V_to_M, M_to_D)\n",
    "d_D = d_M\n",
    "\n",
    "print(V_to_M.shape, M_to_D.shape, D_to_V.shape, M_to_V.shape, V_to_D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a384a33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cat tensor(25.1970)\n",
      "   cat                       634.8876953125\n",
      "   cats                  404.85211181640625\n",
      "   Cat                        401.826171875\n",
      "  Cat                    327.85736083984375\n",
      "  cat                     311.1290283203125\n",
      "   Cats                   273.6062316894531\n",
      "   dog                   254.74285888671875\n",
      "   CAT                      220.56103515625\n",
      "  cats                   218.95774841308594\n",
      "   catcher                 211.718994140625\n",
      "   kittens               210.29351806640625\n",
      "   kitten                202.44485473632812\n",
      "   dogs                  166.30856323242188\n",
      "   animal                 162.6132049560547\n",
      "   pet                   160.79998779296875\n",
      "   goat                    159.751220703125\n",
      "   Dog                   155.82252502441406\n",
      "   rabbit                155.04403686523438\n",
      "   tiger                  149.2018280029297\n",
      "   fel                   142.49505615234375\n",
      "\n",
      " war tensor(23.9921)\n",
      "   war                      575.61865234375\n",
      "   War                   425.15631103515625\n",
      "   wars                   322.0653381347656\n",
      "  war                    319.39300537109375\n",
      "  War                    255.40916442871094\n",
      "   battle                  245.843505859375\n",
      "   conflict              210.33029174804688\n",
      "   Wars                  208.31544494628906\n",
      "   warfare               205.07339477539062\n",
      "   WAR                   202.30018615722656\n",
      "   warrior               170.71511840820312\n",
      "   warriors              167.01564025878906\n",
      "   genocide              164.62213134765625\n",
      "   Battle                  162.943603515625\n",
      "   battlefield               162.6767578125\n",
      "   peace                 161.00888061523438\n",
      "   fight                 159.59317016601562\n",
      "   wartime               159.25033569335938\n",
      "   waging                 157.4219970703125\n",
      "   Vietnam               151.79493713378906\n",
      "\n",
      " banana tensor(32.2420)\n",
      "   banana                   1039.5439453125\n",
      "   bananas                527.4841918945312\n",
      "   Banana                 441.7322082519531\n",
      "   mango                 323.65460205078125\n",
      "   pineapple             319.59832763671875\n",
      "   apple                   285.024658203125\n",
      "   strawberry            279.93316650390625\n",
      "   potato                       261.5859375\n",
      "   coconut                 247.907470703125\n",
      "   peanut                 238.2726287841797\n",
      "   avocado               234.76437377929688\n",
      "   chocolate              227.3436737060547\n",
      "   peach                 217.92117309570312\n",
      "   strawberries          213.66012573242188\n",
      "   gorilla               210.70745849609375\n",
      "   tomato                210.07391357421875\n",
      "   fruit                 207.02908325195312\n",
      "   cinnamon              200.58363342285156\n",
      "   monkey                198.89666748046875\n",
      "   lemon                 196.23513793945312\n",
      "\n",
      " bat tensor(25.4735)\n",
      "   bat                    648.8990478515625\n",
      "   bats                  387.65301513671875\n",
      "   Bat                   266.83990478515625\n",
      "  Bat                    264.54302978515625\n",
      "  bat                     225.3284454345703\n",
      "   batted                 181.1290283203125\n",
      "  BAT                    175.74090576171875\n",
      "   BAT                    172.6558837890625\n",
      "   batting               159.59515380859375\n",
      "   bowling                151.5093994140625\n",
      "   glove                 144.93539428710938\n",
      "   Batman                136.44549560546875\n",
      "   cricket                  135.13916015625\n",
      "   bathing                 133.695556640625\n",
      "   baseball              133.21446228027344\n",
      "   Orioles                133.0828399658203\n",
      "  bats                   131.95896911621094\n",
      "   BA                    130.58914184570312\n",
      "   mouse                 128.51626586914062\n",
      "   bird                  124.69609069824219\n",
      "\n",
      " lie tensor(23.3331)\n",
      "   lie                    544.4324951171875\n",
      "   lies                  406.36920166015625\n",
      "   lying                   276.758544921875\n",
      "   falsehood              259.7517395019531\n",
      "   Lie                   223.21237182617188\n",
      "   lied                  212.20425415039062\n",
      "   Lies                  208.51393127441406\n",
      "   liar                   196.2603302001953\n",
      "   deception              192.8304901123047\n",
      "  Lie                    187.68801879882812\n",
      "   rests                  179.8903045654297\n",
      "   lay                   165.44757080078125\n",
      "   reside                 161.6131134033203\n",
      "   sit                   153.06851196289062\n",
      "   lays                  151.84739685058594\n",
      "   lur                   146.25469970703125\n",
      "   fabrication            140.2855987548828\n",
      "   fabricated                139.7666015625\n",
      "   untrue                  134.166259765625\n",
      "   sleeps                129.60743713378906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_tokens = [' cat', ' war', ' banana', ' bat', ' lie']\n",
    "\n",
    "def print_similar(heading, td):\n",
    "    print(heading, torch.linalg.vector_norm(td))\n",
    "    similarity_vec = torch.matmul(V_to_D, td)\n",
    "    values = [(v.item(), i) for i,v in enumerate(similarity_vec)]\n",
    "    values.sort(reverse=True)\n",
    "    for v,i in values[:20]:\n",
    "        print(f'  {decode(i):20}', f'{v:20}')\n",
    "    print()\n",
    "\n",
    "for tok in example_tokens:\n",
    "    t, = encode(tok)\n",
    "    td = V_to_D[t,:]\n",
    "    print_similar(tok, td)\n",
    "\n",
    "#generator = torch.random.manual_seed(12345)\n",
    "#for i in range(3):\n",
    "#    tr = torch.zeros((d_D))\n",
    "#    tr.normal_(generator=generator)\n",
    "#    tr = tr ** 5\n",
    "#    print_similar('(random)', tr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
