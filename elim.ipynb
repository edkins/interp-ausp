{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0882396c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giles/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Loading model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model gpt2 into EasyTransformer!\n",
      "Moving model to device:  cpu\n",
      "torch.Size([768, 50257]) 768 50257\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from easy_transformer import EasyTransformer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print(f\"Using {device} device\")\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "model = EasyTransformer.from_pretrained('gpt2').to(device)\n",
    "\n",
    "# Convenience function for decoding token\n",
    "decode = model.tokenizer.decode\n",
    "\n",
    "# Convenience function for encoding token\n",
    "def encode(t):\n",
    "    global model\n",
    "    result = model.tokenizer.encode(t)\n",
    "    if len(result) != 1:\n",
    "        raise Exception(f\"Not a single token: {t}\")\n",
    "    return result[0]\n",
    "\n",
    "unembed = model.unembed.W_U.data\n",
    "embed = model.embed.W_E.data\n",
    "d_M = model.cfg.d_model\n",
    "d_V = model.cfg.d_vocab\n",
    "\n",
    "print(unembed.shape, d_M, d_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94b1249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giles/.local/lib/python3.10/site-packages/sklearn/decomposition/_dict_learning.py:208: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  new_code = orthogonal_mp_gram(\n",
      "/home/giles/.local/lib/python3.10/site-packages/sklearn/decomposition/_dict_learning.py:208: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  new_code = orthogonal_mp_gram(\n",
      "/home/giles/.local/lib/python3.10/site-packages/sklearn/decomposition/_dict_learning.py:208: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  new_code = orthogonal_mp_gram(\n",
      "/home/giles/.local/lib/python3.10/site-packages/sklearn/decomposition/_dict_learning.py:208: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  new_code = orthogonal_mp_gram(\n",
      "/home/giles/.local/lib/python3.10/site-packages/sklearn/decomposition/_dict_learning.py:208: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  new_code = orthogonal_mp_gram(\n",
      "/home/giles/.local/lib/python3.10/site-packages/sklearn/decomposition/_dict_learning.py:208: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  new_code = orthogonal_mp_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: 112.50882720947266, 20: 110.68318176269531, 30: 109.38329315185547, 40: 108.73686981201172, 50: 108.18726348876953, 60: 107.76912689208984, 70: 107.38787841796875, 80: 107.11817932128906, 90: 106.91816711425781}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giles/.local/lib/python3.10/site-packages/sklearn/decomposition/_dict_learning.py:208: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  new_code = orthogonal_mp_gram(\n"
     ]
    }
   ],
   "source": [
    "# Choose a random set of tokens (TODO: do better than random)\n",
    "import random\n",
    "from sklearn.decomposition import SparseCoder\n",
    "\n",
    "def gen_and_eval_dict(n_dict, n_eval=1000, n_coefs=5):\n",
    "    random.seed(12345)\n",
    "    indices = torch.tensor(random.sample(range(d_V), k=n_dict))\n",
    "    #print([decode(i) for i in indices[:10]])\n",
    "\n",
    "    dictionary = embed[indices,:]\n",
    "    #print(dictionary.shape)\n",
    "    \n",
    "    eval_ts = torch.tensor(random.sample(range(d_V), k=n_eval))\n",
    "    vs = embed[eval_ts,:]\n",
    "    sc = SparseCoder(dictionary=dictionary, transform_n_nonzero_coefs=n_coefs, transform_algorithm='omp')\n",
    "    transformed = torch.tensor(sc.transform(vs))\n",
    "    \n",
    "    #print(transformed.shape, dictionary.shape)\n",
    "    reconstituted = torch.matmul(transformed, dictionary)\n",
    "    error = torch.linalg.matrix_norm(reconstituted - vs)\n",
    "    \n",
    "    return dictionary, sc, indices, error\n",
    "    \n",
    "errors = {}\n",
    "for n_dict in range(10, 100, 10):\n",
    "    errors[n_dict] = gen_and_eval_dict(n_dict, n_coefs=5)[3].item()\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c132f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giles/.local/lib/python3.10/site-packages/sklearn/decomposition/_dict_learning.py:208: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  new_code = orthogonal_mp_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ peace+++\n",
      "      settlers            0.17874906957149506\n",
      "      conscience          0.16404199600219727\n",
      "      cessation           0.14536640048027039\n",
      "     ï¿½                    0.11943838745355606\n",
      "     afety                0.061829060316085815\n",
      "+++ love+++\n",
      "      hatred              0.32344797253608704\n",
      "     -                    0.17184175550937653\n",
      "      goodness            0.12907937169075012\n",
      "      Beautiful           0.11889779567718506\n",
      "     favorite             0.09814704209566116\n",
      "+++ war+++\n",
      "      fight               0.29392004013061523\n",
      "      hatred              0.2270224690437317\n",
      "      troop               0.16807401180267334\n",
      "      arms                0.15888924896717072\n",
      "      Github              -0.12153104692697525\n",
      "+++ cat+++\n",
      "      rabbits             0.18691937625408173\n",
      "      bas                 0.1638754904270172\n",
      "      sch                 0.16002868115901947\n",
      "      catch               0.14967380464076996\n",
      "      fel                 0.14380015432834625\n",
      "+++ dog+++\n",
      "      monkey              0.2523578107357025\n",
      "      Breed               0.19182555377483368\n",
      "      toddler             0.18195156753063202\n",
      "      yoga                0.14545971155166626\n",
      "      Mb                  -0.09716258943080902\n",
      "+++ Mario+++\n",
      "      Messi               0.18726110458374023\n",
      "      Nathan              0.180242121219635\n",
      "      Archie              0.17076432704925537\n",
      "     Pin                  0.1328938752412796\n",
      "     ModLoader            0.050946194678545\n",
      "+++ Giles+++\n",
      "      Leeds               0.23564401268959045\n",
      "      Garcia              0.2253810316324234\n",
      "      Kelvin              0.17209027707576752\n",
      "     ridges               0.12295118719339371\n",
      "      caut                0.11139796674251556\n"
     ]
    }
   ],
   "source": [
    "# Choose another set of tokens\n",
    "toks = [' peace', ' love', ' war', ' cat', ' dog', ' Mario', ' Giles']\n",
    "ts = torch.tensor([encode(tok) for tok in toks])\n",
    "n_t = len(ts)\n",
    "vs = embed[ts,:]    # gather lookup\n",
    "\n",
    "dictionary, sc, indices, _ = gen_and_eval_dict(2000)\n",
    "\n",
    "last_tok = None\n",
    "transformed = torch.tensor(sc.transform(vs))\n",
    "for i in range(n_t):\n",
    "    v = embed[ts[i],:]\n",
    "    \n",
    "    print(f'+++{toks[i]}+++')\n",
    "    nz = torch.nonzero(transformed[i,:])\n",
    "    values = [(transformed[i,j].item(), decode(indices[j.item()])) for j in nz]\n",
    "    values.sort(reverse=True)\n",
    "    for val, tok in values:\n",
    "        print('    ', f'{tok:20}', val)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
