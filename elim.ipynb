{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68ae8388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Loading model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model gpt2 into EasyTransformer!\n",
      "Moving model to device:  cpu\n",
      "torch.Size([768, 50257]) 768 50257\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from easy_transformer import EasyTransformer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print(f\"Using {device} device\")\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "model = EasyTransformer.from_pretrained('gpt2').to(device)\n",
    "\n",
    "# Convenience function for decoding token\n",
    "decode = model.tokenizer.decode\n",
    "\n",
    "# Convenience function for encoding token\n",
    "def encode(t):\n",
    "    global model\n",
    "    result = model.tokenizer.encode(t)\n",
    "    if len(result) != 1:\n",
    "        raise Exception(f\"Not a single token: {t}\")\n",
    "    return result[0]\n",
    "\n",
    "unembed = model.unembed.W_U.data\n",
    "embed = model.embed.W_E.data\n",
    "d_M = model.cfg.d_model\n",
    "d_V = model.cfg.d_vocab\n",
    "\n",
    "print(unembed.shape, d_M, d_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1581c117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' savage', 'Magn', 'ian', './', ' Grove', ' Others', ' faction', 'omsky', 'ewitness', ' Atlantic']\n",
      "torch.Size([2000, 768])\n"
     ]
    }
   ],
   "source": [
    "# Choose a random set of tokens (TODO: do better than random)\n",
    "import random\n",
    "n_dict = 2000\n",
    "random.seed(12345)\n",
    "indices = torch.tensor(random.sample(range(d_V), k=n_dict))\n",
    "print([decode(i) for i in indices[:10]])\n",
    "\n",
    "dictionary = embed[indices,:]\n",
    "print(dictionary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55c95d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 768])\n",
      "+++ peace+++\n",
      "      settlers            0.17874906957149506\n",
      "      conscience          0.16404199600219727\n",
      "      cessation           0.14536640048027039\n",
      "     ï¿½                    0.11943838745355606\n",
      "     afety                0.061829060316085815\n",
      "3.0729010105133057\n",
      "+++ love+++\n",
      "      hatred              0.32344797253608704\n",
      "     -                    0.17184175550937653\n",
      "      goodness            0.12907937169075012\n",
      "      Beautiful           0.11889779567718506\n",
      "     favorite             0.09814704209566116\n",
      "2.5666236877441406\n",
      "+++ war+++\n",
      "      fight               0.29392004013061523\n",
      "      hatred              0.2270224690437317\n",
      "      troop               0.16807401180267334\n",
      "      arms                0.15888924896717072\n",
      "      Github              -0.12153104692697525\n",
      "2.557136297225952\n",
      "+++ cat+++\n",
      "      rabbits             0.18691937625408173\n",
      "      bas                 0.1638754904270172\n",
      "      sch                 0.16002868115901947\n",
      "      catch               0.14967380464076996\n",
      "      fel                 0.14380015432834625\n",
      "2.700529098510742\n",
      "+++ dog+++\n",
      "      monkey              0.2523578107357025\n",
      "      Breed               0.19182555377483368\n",
      "      toddler             0.18195156753063202\n",
      "      yoga                0.14545971155166626\n",
      "      Mb                  -0.09716258943080902\n",
      "2.54441499710083\n",
      "+++ Mario+++\n",
      "      Messi               0.18726110458374023\n",
      "      Nathan              0.180242121219635\n",
      "      Archie              0.17076432704925537\n",
      "     Pin                  0.1328938752412796\n",
      "     ModLoader            0.050946194678545\n",
      "2.8900949954986572\n",
      "+++ Giles+++\n",
      "      Leeds               0.23564401268959045\n",
      "      Garcia              0.2253810316324234\n",
      "      Kelvin              0.17209027707576752\n",
      "     ridges               0.12295118719339371\n",
      "      caut                0.11139796674251556\n",
      "3.203103542327881\n"
     ]
    }
   ],
   "source": [
    "# Choose another set of tokens\n",
    "toks = [' peace', ' love', ' war', ' cat', ' dog', ' Mario', ' Giles']\n",
    "ts = torch.tensor([encode(tok) for tok in toks])\n",
    "n_t = len(ts)\n",
    "vs = embed[ts,:]    # gather lookup\n",
    "print(vs.shape)\n",
    "\n",
    "from sklearn.decomposition import SparseCoder\n",
    "transformed = torch.tensor(SparseCoder(dictionary=dictionary, transform_n_nonzero_coefs=5).transform(vs))\n",
    "last_tok = None\n",
    "for i in range(n_t):\n",
    "    print(f'+++{toks[i]}+++')\n",
    "    nz = torch.nonzero(transformed[i,:])\n",
    "    values = [(transformed[i,j].item(), decode(indices[j.item()])) for j in nz]\n",
    "    values.sort(reverse=True)\n",
    "    for val, tok in values:\n",
    "        print('    ', f'{tok:20}', val)\n",
    "    \n",
    "    v = embed[ts[i],:]\n",
    "    reconstituted = torch.matmul(transformed[i,:], dictionary)\n",
    "    #print(v[:20])\n",
    "    #print(reconstituted[:20])\n",
    "    print(torch.linalg.vector_norm(v - reconstituted).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
