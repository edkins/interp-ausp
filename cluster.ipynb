{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207fcefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Loading model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giles/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model gpt2 into EasyTransformer!\n",
      "Moving model to device:  cpu\n",
      "torch.Size([768, 50257]) torch.Size([50257, 768]) 768 50257\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from easy_transformer import EasyTransformer\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print(f\"Using {device} device\")\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "model = EasyTransformer.from_pretrained('gpt2').to(device)\n",
    "\n",
    "# Convenience function for decoding token\n",
    "decode = model.tokenizer.decode\n",
    "\n",
    "# Convenience function for encoding token\n",
    "def encode(t):\n",
    "    global model\n",
    "    result = model.tokenizer.encode(t)\n",
    "    if len(result) != 1:\n",
    "        raise Exception(f\"Not a single token: {t}\")\n",
    "    return result[0]\n",
    "\n",
    "unembed = model.unembed.W_U.data\n",
    "embed = model.embed.W_E.data\n",
    "d_M = model.cfg.d_model\n",
    "d_V = model.cfg.d_vocab\n",
    "\n",
    "print(unembed.shape, embed.shape, d_M, d_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9af78569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "unembed_norm = torch.nn.functional.normalize(unembed, dim=0)\n",
    "cluster_indices = KMeans(n_clusters=50).fit_predict(unembed_norm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ffbf899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ cluster 0+++\n",
      "['holm', 'v', 'mega', 'imgur', 'dr', 'len', 'riot', 'nas', 'mas', 'thy']\n",
      "+++ cluster 1+++\n",
      "[' its', ' meaning', ' least', ' elsewhere', ' courtesy', ' —', ' beneath', ' anymore', ' those', ' itself']\n",
      "+++ cluster 2+++\n",
      "[' Fork', ' Pour', ' Thursday', ' Bin', ' Warn', ' Lot', ' Grove', ' Bub', ' Cre', ' Set']\n",
      "+++ cluster 3+++\n",
      "[' nicotine', ' tum', ' amp', ' psycho', ' gravitational', ' prote', ' vaccinated', ' arter', ' flu', ' rodents']\n",
      "+++ cluster 4+++\n",
      "['Brother', 'J', 'R', 'Legend', 'Revolution', 'Iron', 'Spell', 'Pub', 'Tumblr', 'Republic']\n",
      "+++ cluster 5+++\n",
      "[' dim', ' cer', ' null', ' iso', ' pap', ' inv', ' fur', ' feat', ' javascript', ' fab']\n",
      "+++ cluster 6+++\n",
      "[' Planned', ' Championships', ' Governors', ' Clubs', ' Film', ' Special', ' Cabin', ' Associates', ' Republican', ' Budget']\n",
      "+++ cluster 7+++\n",
      "[' +++', ' ©', '<<', ' �', '/-', 'Ã', '—\"', 'soever', ':', '.']\n",
      "+++ cluster 8+++\n",
      "[' striking', ' combating', ' wanting', ' surfing', ' caring', ' writing', ' unfolding', ' evolving', ' terminating', ' coaching']\n",
      "+++ cluster 9+++\n",
      "['forums', 'game', 'let', 'washing', 'eye', 'birds', 'jobs', 'fight', 'mask', 'mate']\n",
      "+++ cluster 10+++\n",
      "[' troublesome', ' precious', ' deadly', ' hesitant', ' disturbing', ' manipulative', ' sober', ' unwilling', ' hilar', ' brave']\n",
      "+++ cluster 11+++\n",
      "[' mountains', ' meteor', ' pipeline', ' hive', ' west', ' junction', ' salon', ' camp', ' garden', ' wildfire']\n",
      "+++ cluster 12+++\n",
      "[' telecommunications', ' constitutional', ' counterterrorism', ' enforcement', ' enterprise', ' sectarian', ' generational', ' privat', ' college', ' interstellar']\n",
      "+++ cluster 13+++\n",
      "['Remote', 'Listener', 'Feed', 'AppData', 'Nothing', 'Our', 'Shortly', 'Extra', 'True', 'Physical']\n",
      "+++ cluster 14+++\n",
      "[' 136', ' 1440', ' 188', ' 332', ' 423', ' 358', ' 430', ' 93', ' 52', ' 366']\n",
      "+++ cluster 15+++\n",
      "[' Formation', ' Prep', ' Seeds', ' Ammunition', ' Obj', ' Destroy', ' Guests', ' Subject', ' Animated', ' Interactive']\n",
      "+++ cluster 16+++\n",
      "['pair', 'imposed', 'changing', 'report', 'println', 'kernel', 'aligned', 'bodied', 'agency', 'operator']\n",
      "+++ cluster 17+++\n",
      "['itect', 'endix', 'antically', 'inate', 'ircraft', 'porate', 'angible', 'othal', 'rations', 'onsense']\n",
      "+++ cluster 18+++\n",
      "[' THIS', ' WOR', ' BIT', ' ALWAYS', ' ED', ' FIRST', ' SUR', ' LIFE', ' LIC', ' VER']\n",
      "+++ cluster 19+++\n",
      "[' beams', ' knots', ' rifles', ' oils', ' jails', ' belts', ' medals', ' tracks', ' hotels', ' monkeys']\n",
      "+++ cluster 20+++\n",
      "[' certainly', ' partially', ' efficiently', ' deeply', ' intrinsically', ' really', ' duly', ' fiercely', ' religiously', ' emphatically']\n",
      "+++ cluster 21+++\n",
      "[' visual', ' personal', ' stronger', ' partial', ' environmentally', ' widest', ' adverse', ' decisive', ' intricate', ' steep']\n",
      "+++ cluster 22+++\n",
      "[' nationals', ' enterprises', ' inspectors', ' teachers', ' interns', ' campuses', ' justices', ' residents', ' jihadists', ' tribes']\n",
      "+++ cluster 23+++\n",
      "[' Wolver', ' Cox', ' Reich', ' Booth', ' Fuller', ' Ernst', ' Camden', ' Weaver', ' Lew', ' Fry']\n",
      "+++ cluster 24+++\n",
      "['ars', 'erk', 'all', 'ander', 'yth', 'ords', 'ie', 'aut', 'arg', 'aws']\n",
      "+++ cluster 25+++\n",
      "[' fallen', ' regained', ' deployed', ' switched', ' dispersed', ' forgiven', ' arose', ' hired', ' starved', ' evaluated']\n",
      "+++ cluster 26+++\n",
      "[' suggest', ' agree', ' recommend', ' vanish', ' deny', ' omit', ' defy', ' inhibit', ' bask', \"'ve\"]\n",
      "+++ cluster 27+++\n",
      "[' Angelo', ' Jorge', ' Wayne', ' Juliet', ' Giul', ' Cliff', ' Cornel', ' Abby', ' Kyle', ' Leah']\n",
      "+++ cluster 28+++\n",
      "[' 1919', ' 2050', ' September', ' 1955', ' June', ' 1914', ' 1954', ' 1909', ' 1893', ' 2013']\n",
      "+++ cluster 29+++\n",
      "['468', '886', '551', '365', '696', '684', '657', '644', '787', '572']\n",
      "+++ cluster 30+++\n",
      "[' Gladiator', ' Divine', ' Costume', ' Wings', ' Romance', ' Panthers', ' Seah', ' Enix', ' Kitty', ' Cloud']\n",
      "+++ cluster 31+++\n",
      "[' goes', ' entert', ' sleeps', ' refers', ' ignores', ' feels', ' illustrates', ' cites', ' violates', ' includes']\n",
      "+++ cluster 32+++\n",
      "[' Congo', ' Ottawa', ' Taiwan', ' Memphis', ' Honolulu', ' Chattanooga', ' Harvard', ' Niger', ' Hindus', ' Ethiopia']\n",
      "+++ cluster 33+++\n",
      "[' enjoyment', ' undue', ' conscience', ' ambition', ' consolation', ' folklore', ' afterlife', ' coincidence', ' enthusiasm', ' blindness']\n",
      "+++ cluster 34+++\n",
      "['zzo', 'uary', 'anu', 'uda', 'ima', 'abba', 'agos', 'iami', 'anon', 'ahime']\n",
      "+++ cluster 35+++\n",
      "[' oblig', ' dram', ' divid', ' timet', ' traff', ' enact', ' dispar', ' irre', ' inval', ' resent']\n",
      "+++ cluster 36+++\n",
      "[' groundwork', ' inclination', ' dependence', ' diversion', ' authorization', ' shipment', ' examination', ' diligence', ' simplicity', ' uniqueness']\n",
      "+++ cluster 37+++\n",
      "[' deployments', ' expectations', ' dinners', ' resources', ' audits', ' empires', ' aspirations', ' bonuses', ' inspections', ' contrasts']\n",
      "+++ cluster 38+++\n",
      "[' Jar', ' Moj', ' Jiu', ' Mong', ' Ard', ' Vive', ' Socrates', ' Ragnar', ' Sharma', ' Eucl']\n",
      "+++ cluster 39+++\n",
      "[' FT', ' NV', ' LinkedIn', ' UTF', ' SPD', ' DT', ' Windows', ' AAP', ' OS', ' AAC']\n",
      "+++ cluster 40+++\n",
      "['EB', 'IK', 'AMD', 'IM', 'LIN', 'HO', 'FIN', 'FUL', 'OA', 'FORM']\n",
      "+++ cluster 41+++\n",
      "['�', '龍�', '\\x07', '\\x0e', ' teasp', '�', '�', '\\x00', ' carbohyd', ' newcom']\n",
      "+++ cluster 42+++\n",
      "[' Damn', ' Millions', ' Many', ' Too', ' About', ' Like', ' Prepare', ' Says', ' Known', ' Several']\n",
      "+++ cluster 43+++\n",
      "[' spam', ' crack', ' move', ' boot', ' dash', ' leak', ' haircut', ' purse', ' squeeze', ' shake']\n",
      "+++ cluster 44+++\n",
      "[' mogul', ' frontrunner', ' detainee', ' blogger', ' contestant', ' advertis', ' rabbi', ' lawyer', ' destroyer', ' smoker']\n",
      "+++ cluster 45+++\n",
      "['2200', '42', '143', '13', '1007', '36', '49', '2000', '1976', '2004']\n",
      "+++ cluster 46+++\n",
      "[' curv', ' apples', ' parchment', ' gluten', ' hamm', ' bath', ' clay', ' platinum', ' laure', ' butter']\n",
      "+++ cluster 47+++\n",
      "[' shader', ' birthday', ' month', ' seminar', ' description', ' top', ' valve', ' hardware', ' tablet', ' label']\n",
      "+++ cluster 48+++\n",
      "['Phill', 'Donnell', 'Lyn', 'Ian', 'Disney', 'Liverpool', 'South', 'Austin', 'Ohio', 'Minnesota']\n",
      "+++ cluster 49+++\n",
      "['�', '装', 'シャ', 'セ', 'ッ', '�', 'к', '�', ' 神', 'ギ']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "random.seed(12345)\n",
    "bins = defaultdict(list)\n",
    "for t in range(d_V):\n",
    "    cluster = cluster_indices[t]\n",
    "    bins[cluster].append(t)\n",
    "for b in sorted(bins.keys()):\n",
    "    print(f'+++ cluster {b}+++')\n",
    "    show = random.sample(bins[b], k=10)\n",
    "    print([decode(t) for t in show])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1a6beb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.decomposition import PCA\n",
    "unembed_norm = torch.nn.functional.normalize(unembed, dim=0)\n",
    "ball_tree0 = BallTree(unembed_norm.T)\n",
    "unembed_norm = torch.nn.functional.normalize(unembed, dim=1)\n",
    "ball_tree1 = BallTree(unembed_norm.T)\n",
    "\n",
    "#pca = PCA(n_components=d_M)\n",
    "#unembed_pca = pca.fit_transform(unembed)\n",
    "#ball_tree2 = BallTree(unembed_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b1d1b5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ peace+++\n",
      "      peace                peace              \n",
      "      Peace                Peace              \n",
      "     peace                peace               \n",
      "     Peace                Peace               \n",
      "      peaceful             peaceful           \n",
      "      ceasefire            truce              \n",
      "      truce                peac               \n",
      "      peac                 tranqu             \n",
      "      tranqu               ceasefire          \n",
      "      freedom              peacefully         \n",
      "      war                  pacif              \n",
      "      prosperity           freedom            \n",
      "      pacif                war                \n",
      "      security             harmony            \n",
      "      happiness            security           \n",
      "      harmony              unity              \n",
      "      calm                 prosperity         \n",
      "      peacefully           reconciliation     \n",
      "      unity                calm               \n",
      "      conflict             happiness          \n",
      "+++ love+++\n",
      "      love                 love               \n",
      "      LOVE                 LOVE               \n",
      "      loves               love                \n",
      "      Love                 Love               \n",
      "      loved                loves              \n",
      "      loving               loved              \n",
      "      hate                 loving             \n",
      "      passion             Love                \n",
      "     love                  adore              \n",
      "      adore                hate               \n",
      "      affection            passion            \n",
      "      romance              affection          \n",
      "     Love                  romance            \n",
      "      desire               lover              \n",
      "      romantic             dislike            \n",
      "      hatred               friendship         \n",
      "      joy                  hatred             \n",
      "      dislike              joy                \n",
      "      lover                romantic           \n",
      "      want                 lovers             \n",
      "+++ war+++\n",
      "      war                  war                \n",
      "      War                  wars               \n",
      "      wars                 War                \n",
      "      warfare             war                 \n",
      "      battle               warfare            \n",
      "     war                  War                 \n",
      "      conflict             battle             \n",
      "      military             Wars               \n",
      "      wartime              conflict           \n",
      "      combat               WAR                \n",
      "     War                   wartime            \n",
      "      peace                peace              \n",
      "      army                 battles            \n",
      "      battles              military           \n",
      "      battlefield          battlefield        \n",
      "      warrior              combat             \n",
      "      fight                militar            \n",
      "      Wars                 army               \n",
      "      militar              Warfare            \n",
      "      WAR                  hostilities        \n",
      "+++ cat+++\n",
      "      cat                  cat                \n",
      "      cats                 cats               \n",
      "      Cat                  Cat                \n",
      "      dog                 cat                 \n",
      "     cat                  Cat                 \n",
      "      kitten               Cats               \n",
      "     Cat                   dog                \n",
      "      pet                  kitten             \n",
      "      Cats                cats                \n",
      "      kittens              CAT                \n",
      "      CAT                  kittens            \n",
      "      rabbit               rabbit             \n",
      "      animal               pet                \n",
      "      catcher              catcher            \n",
      "      tiger                animal             \n",
      "      ch                   tiger              \n",
      "      rat                  dogs               \n",
      "      dogs                 rat                \n",
      "      chicken              pets               \n",
      "      pig                  goat               \n",
      "+++ dog+++\n",
      "      dog                  dog                \n",
      "      dogs                 dogs               \n",
      "      canine               Dog                \n",
      "      Dog                  canine             \n",
      "      puppy               dog                 \n",
      "      animal               puppy              \n",
      "      pet                  Dogs               \n",
      "      cat                 Dog                 \n",
      "      horse                animal             \n",
      "      Dogs                 pet                \n",
      "     dog                   puppies            \n",
      "      pets                 cat                \n",
      "      puppies              pets               \n",
      "      wolf                dogs                \n",
      "      cats                 pup                \n",
      "      pup                  horse              \n",
      "      snake                leash              \n",
      "      animals              cats               \n",
      "      barking              wolf               \n",
      "      bird                 barking            \n",
      "+++ leaves+++\n",
      "      leaves               leaves             \n",
      "      Leaves               Leaves             \n",
      "      leave                leave              \n",
      "      leaving              leaf               \n",
      "      leaf                 stems              \n",
      "      stems                foliage            \n",
      "      left                 leaving            \n",
      "      makes                left               \n",
      "      foliage              ends               \n",
      "      ends                 flowers            \n",
      "      puts                 shoots             \n",
      "      drops                plants             \n",
      "      falls               leaf                \n",
      "      flowers              Leaf               \n",
      "      gives                flies              \n",
      "      plants               drops              \n",
      "      reaches              branches           \n",
      "      remains              begs               \n",
      "      takes                exits              \n",
      "      raises               hides              \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "toks = [' peace', ' love', ' war', ' cat', ' dog', ' leaves']\n",
    "ts = [encode(tok) for tok in toks]\n",
    "v = unembed[:,ts].T\n",
    "d0,q0 = ball_tree0.query(v, k=20, return_distance=True)\n",
    "d1,q1 = ball_tree1.query(v, k=20, return_distance=True)\n",
    "for i,tok in enumerate(toks):\n",
    "    print(f'+++{tok}+++')\n",
    "    for j,(t0,t1) in enumerate(zip(q0[i,:],q1[i,:])):\n",
    "        print('    ', f'{decode(t0):20}', f'{decode(t1):20}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
